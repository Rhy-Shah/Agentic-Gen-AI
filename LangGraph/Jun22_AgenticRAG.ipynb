{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d2073d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from langgraph.types import Command\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.tools import tool\n",
    "from typing_extensions import Literal\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac255335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! I'm just a virtual assistant, so I don't have feelings, but I'm here to help you. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 14, 'total_tokens': 45, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Bnt4QZfRJYA7dNXOFmog4sPSNCDBD', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--23e1b8e0-3781-4ea9-8200-c25e7dc07da9-0', usage_metadata={'input_tokens': 14, 'output_tokens': 31, 'total_tokens': 45, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "llm.invoke(\"Hey there, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2f5a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_number(state):\n",
    "    result = state[\"num1\"] + state[\"num2\"]\n",
    "    print(f\"addition is {result}\")\n",
    "    \n",
    "    return Command(goto = \"multiply\", update = {\"sum\": result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a27eabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addition is 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Command(update={'sum': 15}, goto='multiply')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = {\"num1\": 5, \"num2\": 10}\n",
    "add_number(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f67796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def transfer_to_addition_expert():\n",
    "    \"\"\"Ask addition agent for help\"\"\"\n",
    "    return\n",
    "\n",
    "@tool\n",
    "def transfer_to_multiplication_expert():\n",
    "    \"\"\"Ask multiplication agent for help\"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b00b4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tool = llm.bind_tools([transfer_to_multiplication_expert, transfer_to_addition_expert])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79ca6bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm_with_tool.invoke(\"What is 5 + 10?\")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf5eb44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'transfer_to_addition_expert',\n",
       "  'args': {},\n",
       "  'id': 'call_b4IltmQfM5PY5wZAimecaEpQ',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3f7ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\"You are an addition expert, you can ask the multiplication expert for help with multiplication\"\n",
    "                 \"Always do your portion of calculation first, then ask the multiplication expert if needed\")\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [\"Can you add 5 and 10?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7bdc55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an addition expert, you can ask the multiplication expert for help with multiplicationAlways do your portion of calculation first, then ask the multiplication expert if needed'},\n",
       " 'Can you add 5 and 10?']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "368c5087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addition_agent(state: MessagesState) -> Command[Literal[\"multiplication_agent\", \"__end__\"]]:\n",
    "    system_prompt = \"You are an addition expert, and you can ask for help from the multiplication expert when asked to multiply numbers.Always do your portion of calculation first, and then ask the multiplication expert if needed.\"\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "    \n",
    "    llm = llm.bind_tools([transfer_to_multiplication_expert])\n",
    "    ai_message = llm.invoke(messages)\n",
    "    \n",
    "    if len(ai_message.tool_calls) > 0:\n",
    "        tool_call_id = ai_message.tool_calls[-1].id\n",
    "        tool_message = {\"role\": \"tool\", \"content\": \"Successfully transferred to multiplication expert.\", \"tool_call_id\": tool_call_id}\n",
    "\n",
    "        return Command(goto=\"multiplication_agent\", update={\"messages\": messages + [ai_message, tool_message]})\n",
    "\n",
    "    return {\"messages\":[ai_message]}\n",
    "\n",
    "\n",
    "def multiplication_agent(state: MessagesState) -> Command[Literal[\"addition_agent\", \"__end__\"]]:\n",
    "    system_prompt = \"You are a multiplication expert, and you can ask for help from the addition expert when asked to add numbers.Always do your portion of calculation first, and then ask the addition expert if needed.\"\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "    \n",
    "    llm = llm.bind_tools([transfer_to_addition_expert]).invoke(messages)\n",
    "    ai_message = llm.invoke(messages)\n",
    "    \n",
    "    if len(ai_message.tool_calls) > 0:\n",
    "        tool_call_id = ai_message.tool_calls[-1].id\n",
    "        tool_message = {\"role\": \"tool\", \"content\": \"Successfully transferred to addition expert.\", \"tool_call_id\": tool_call_id}\n",
    "\n",
    "        return Command(goto=\"addition_agent\", update={\"messages\": messages + [ai_message, tool_message]})\n",
    "\n",
    "    return {\"messages\":[ai_message]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "516415da",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(MessagesState)\n",
    "\n",
    "graph.add_node(\"addition_agent\", addition_agent)\n",
    "graph.add_node(\"multiplication_agent\", multiplication_agent)\n",
    "\n",
    "graph.add_edge(START, \"addition_agent\")\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e6ddb30",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'llm' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnboundLocalError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m app.invoke({\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [(\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mCan you add 5 and 10?\u001b[39m\u001b[33m\"\u001b[39m)]})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-ArizonaStateUniversity/SelfStudy/Agentic & Gen AI with Cloud/agenticai/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2719\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2716\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2717\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2719\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream(\n\u001b[32m   2720\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   2721\u001b[39m     config,\n\u001b[32m   2722\u001b[39m     stream_mode=stream_mode,\n\u001b[32m   2723\u001b[39m     output_keys=output_keys,\n\u001b[32m   2724\u001b[39m     interrupt_before=interrupt_before,\n\u001b[32m   2725\u001b[39m     interrupt_after=interrupt_after,\n\u001b[32m   2726\u001b[39m     checkpoint_during=checkpoint_during,\n\u001b[32m   2727\u001b[39m     debug=debug,\n\u001b[32m   2728\u001b[39m     **kwargs,\n\u001b[32m   2729\u001b[39m ):\n\u001b[32m   2730\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2731\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2732\u001b[39m             \u001b[38;5;28misinstance\u001b[39m(chunk, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m   2733\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m (ints := chunk.get(INTERRUPT)) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2734\u001b[39m         ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-ArizonaStateUniversity/SelfStudy/Agentic & Gen AI with Cloud/agenticai/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2436\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2434\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2435\u001b[39m             loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2436\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.tick(\n\u001b[32m   2437\u001b[39m             [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop.tasks.values() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.writes],\n\u001b[32m   2438\u001b[39m             timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   2439\u001b[39m             get_waiter=get_waiter,\n\u001b[32m   2440\u001b[39m             schedule_task=loop.accept_push,\n\u001b[32m   2441\u001b[39m         ):\n\u001b[32m   2442\u001b[39m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2443\u001b[39m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[32m   2444\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36maddition_agent\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      2\u001b[39m system_prompt = \u001b[33m\"\u001b[39m\u001b[33mYou are an addition expert, and you can ask for help from the multiplication expert when asked to multiply numbers.Always do your portion of calculation first, and then ask the multiplication expert if needed.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m messages = [{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: system_prompt}] + state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m llm = llm.bind_tools([transfer_to_multiplication_expert])\n\u001b[32m      6\u001b[39m ai_message = llm.invoke(messages)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ai_message.tool_calls) > \u001b[32m0\u001b[39m:\n",
      "\u001b[31mUnboundLocalError\u001b[39m: cannot access local variable 'llm' where it is not associated with a value",
      "During task with name 'addition_agent' and id 'c5b515b9-b3d0-ef88-db77-c2bb4af5b385'"
     ]
    }
   ],
   "source": [
    "app.invoke({\"messages\": [(\"user\", \"Can you add 5 and 10?\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2b5e91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ca005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
