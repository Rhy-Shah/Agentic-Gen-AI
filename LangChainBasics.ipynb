{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f0a41ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d55408f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AgenticAI'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "babbf00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "## This value has to be set to true always\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "660e20be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x112ccc270> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x112ccc6b0> root_client=<openai.OpenAI object at 0x110163df0> root_async_client=<openai.AsyncOpenAI object at 0x112ccc380> model_name='o1-mini' temperature=1.0 model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model = \"o1-mini\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cfda1833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of India is **New Delhi**.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 405, 'prompt_tokens': 14, 'total_tokens': 419, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 384, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o1-mini-2024-09-12', 'system_fingerprint': 'fp_3da8b0b088', 'id': 'chatcmpl-BcnYl0VmfvoyA3feHMYPX1Ikyza3G', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--3b974d13-60de-465c-9e42-3d94a174dfaa-0', usage_metadata={'input_tokens': 14, 'output_tokens': 405, 'total_tokens': 419, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 384}})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.invoke(\"What is the capital of India?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "af8900f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of India is **New Delhi**.'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "61cd5353",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"qwen-qwq-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0600e1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n<think>\\nOkay, the user introduced themselves as Rhythm. I should respond politely and maybe ask how I can assist them today. Let me keep it friendly and open-ended so they feel comfortable to ask for help with whatever they need. Maybe something like, \"Hi Rhythm! How can I assist you today?\" That should work.\\n\\nWait, maybe I should add a bit more to make it welcoming. Maybe mention that I\\'m here to help with any questions or tasks. Let me check the guidelines again to make sure I\\'m following the right tone. Yep, friendly and helpful. Alright, the response should be concise but inviting. Let me go with that.\\n\\n</think>\\n\\nHi Rhythm! Nice to meet you. How can I assist you today? Feel free to ask me any questions or let me know if you need help with anything specific! ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 171, 'prompt_tokens': 16, 'total_tokens': 187, 'completion_time': 0.390734962, 'prompt_time': 0.002900875, 'queue_time': 0.056769559000000004, 'total_time': 0.393635837}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_a91d9c2cfb', 'finish_reason': 'stop', 'logprobs': None}, id='run--d1c38fc6-5d44-45a7-a211-3d6e082bc8da-0', usage_metadata={'input_tokens': 16, 'output_tokens': 171, 'total_tokens': 187})"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Hi, I am Rhythm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640bcb39",
   "metadata": {},
   "source": [
    "### PROMPT ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "448afac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI assistant. Provide me with concise and accurate answers.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt =  ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI assistant. Provide me with concise and accurate answers.\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1e599d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x1134e27b0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x1134e2430>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"gemma2-9b-it\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6b017894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI assistant. Provide me with concise and accurate answers.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x1134e27b0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x1134e2430>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model\n",
    "\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "93a04e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Eiffel Tower was built in 1887-1889 as the entrance arch for the 1889 World's Fair in Paris, celebrating the centennial of the French Revolution. \\n\\nDesigned by Gustave Eiffel and his company, it was initially met with strong opposition from artists and intellectuals who considered it an eyesore. However, it quickly became a beloved symbol of Paris and a global icon. \\n\\nThe tower was initially meant to be dismantled after 20 years but was saved due to its use for radio transmissions.  Today, it's one of the most visited monuments in the world. \\n\\n\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"input\": \"Can you tell me about the history of the Eiffel Tower?\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c36d4fb",
   "metadata": {},
   "source": [
    "### Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2af09fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bb3e560b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"input\": \"What is the capital of France?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "df7f28d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(template = \"Answer the user query \\n {format_instructions} \\n {input} \\n\", input_variables = [\"query\"], \n",
    "                        partial_variables = {\"format_instructions\": output_parser.get_format_instructions()})\n",
    "\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8ea2f96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Bitcoin is a decentralized digital currency, without a central bank or single administrator, that can be sent from user to user on the peer-to-peer bitcoin network without the need for intermediaries. Transactions are verified by network nodes through cryptography and recorded in a public distributed ledger called a blockchain.', 'key_features': ['Decentralized:', 'Digital:', 'Peer-to-peer:', 'Cryptographically secure:', 'Transparent and immutable ledger (blockchain):', 'Limited supply (21 million bitcoins)'], 'impact_on_finance': ['Alternative to traditional currencies:', 'Potential for faster and cheaper transactions:', 'New investment asset class:', 'Innovation in financial technology'], 'risks': ['Volatility:', 'Security risks:', 'Regulatory uncertainty:', 'Lack of consumer protection']}\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"input\": \"What is Bitcoin in the world of Finance?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d417900",
   "metadata": {},
   "source": [
    "### Using ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "79d80ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant that provides concise and accurate answers. Provide the answer in json format.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant that provides concise and accurate answers. Provide the answer in json format.\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b16fa65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'definition': 'Financial instruments whose value is derived from an underlying asset, such as a stock, bond, commodity, or currency.', 'characteristics': [\"Value fluctuates based on the underlying asset's performance.\", 'Used for hedging, speculation, or arbitrage.', 'Examples include options, futures, swaps, and forwards.']}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | model | output_parser\n",
    "response = chain.invoke({\"input\": \"What are Derivatives in Finance?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f56173",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
